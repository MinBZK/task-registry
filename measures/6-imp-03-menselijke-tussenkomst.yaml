systemcard_path: .systemcard.requirements[]
schema_version: 1.1.0
name: Richt de juiste menselijke controle in van het algoritme
description: 'Richt (technische) controlemechanismen in voor menselijke tussenkomst
  (of: menselijke controle) waarmee de output van een algoritme kan worden gecontroleerd.


  '
explanation: "Algoritmes ondersteunen vaak beslissingen en besluitvorming van overheidsorganisaties.\
  \ Deze beslissingen of besluiten kunnen betrokkenen in [aanmerkelijke mate raken\
  \ of zelfs rechtsgevolgen](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/index.html)\
  \ hebben. Omdat algoritmes niet foutloos zijn, is het belangrijk dat een mens controleert\
  \ wat een algoritme doet en, waar nodig, corrigeert. Dit proces heet 'menselijke\
  \ tussenkomst' en moet betekenisvol zijn, niet slechts symbolisch.\n\nHet inrichten,\
  \ monitoren en evalueren van menselijke controle is cruciaal om te voorkomen dat\
  \ algoritmes negatieve effecten veroorzaken of de menselijke autonomie ondermijnen.\n\
  \nBetekenisvolle menselijke controle houdt in dat:\n\n- Het toezicht wordt uitgevoerd\
  \ door iemand die bevoegd en bekwaam is om een beslissing of besluit te wijzigen.\n\
  - Automatische aanbevelingen niet klakkeloos worden overgenomen. Bijvoorbeeld: een\
  \ systeem dat standaard een suggestie accepteert door een enkele klik voldoet hier\
  \ niet aan.\n- De vormen van menselijke tussenkomst al in een vroeg stadium, bijvoorbeeld\
  \ in de ontwerpfase, worden vastgesteld op basis van risicoanalyses.\n- Gebruikers\
  \ voldoende kennis, tijd en verantwoordelijkheid hebben om weloverwogen beslissingen\
  \ te nemen over het functioneren van algoritmes. Dit betekent ook dat externe factoren,\
  \ zoals tijdsdruk of onvoldoende informatie, de beoordeling van de output niet mogen\
  \ beïnvloeden. (zie ook het [onderzoekskader van de ADR, SV.6](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023))\n\
  \nSoms is menselijke tussenkomst minder relevant, zoals bij ‘gebonden bevoegdheden’.\
  \ Hierbij is weinig tot geen ruimte om een beslissing of besluit aan te passen.\
  \ Voorbeelden zijn:\n\n- Het opleggen van verkeersboetes onder de Wet administratiefrechtelijke\
  \ handhaving verkeersvoorschriften (Wahv).\n- Het automatisch aanpassen van studiefinanciering\
  \ op basis van inkomenswijzigingen.\n\nOm menselijke tussenkomst goed te organiseren,\
  \ zijn technische en organisatorische maatregelen nodig. Dit geldt ook wanneer een\
  \ externe aanbieder de algoritmes levert. In dat geval moet de verantwoordelijke\
  \ organisatie (gebruiksverantwoordelijke) samen met de aanbieder bepalen hoe menselijke\
  \ tussenkomst zinvol kan worden ingericht.\n\n### Inrichten van menselijke controle\n\
  \nEr zijn verschillende manieren om menselijke tussenkomst in te richten, afhankelijk\
  \ van de specifieke toepassing van een algoritme. Hieronder worden vier mogelijkheden\
  \ beschreven die kunnen worden ingezet, los of in combinatie:\n\n#### 1. Human in\
  \ the loop\nBij dit model speelt de mens een actieve rol in elke fase van het algoritme.\
  \ Deze variant geeft de meeste controle en invloed, maar kan leiden tot vertraagde\
  \ of minder efficiënte besluitvorming, vooral bij real-time of zeer complexe taken\
  \ waarbij snelheid cruciaal is.\nEen voorbeeld van toepassen van Human-in-the-loop\
  \ is het nakijken en beoordelen van de output van een algoritme door een mens, telkens\
  \ voordat een beslissing wordt genomen. Het verwerken van data gebeurt alleen in\
  \ opdracht van de mens en verder neemt het algoritme of AI model geen autonome beslissingen.\
  \ \n\n#### 2. Human on the loop\nHier behoudt de mens toezicht en kan ingrijpen\
  \ wanneer dat nodig is, om te garanderen dat een model veilig en ethisch opereert.\
  \ Dit model biedt daardoor een balans tussen autonome besluitvorming en menselijke\
  \ controle. Het is vooral nuttig in situaties waarin afwijkende keuzes of acties\
  \ van het algoritme grote gevolgen kunnen hebben. De menselijke operator houdt de\
  \ werking van het algoritme in de gaten en staat klaar om in te grijpen of beslissingen\
  \ terug te draaien wanneer nodig.\n\n#### 3. Human above the loop\nIn dit model\
  \ houdt de mens toezicht op een hoger niveau, met een focus op strategische en ethische\
  \ keuzes, in plaats van dat de menselijke operator zich bezighoudt met directe operationele\
  \ beslissingen. Dit stelt de mens in staat in te grijpen wanneer kritieke morele,\
  \ juridische of sociale zorgen ontstaan om het model op de langere termijn bij te\
  \ sturen.  De menselijke tussenkomst is gericht op het bepalen van beleid en de\
  \ richtlijnen voor algoritmes. Het gaat daarbij niet alleen over het definiëren\
  \ van operationele procedures maar ook het maken van bepaalde ethische overwegingen,\
  \ het zorgen voor naleving van regelgeving en het overwegen van de implicaties van\
  \ de inzet van algoritmes op de lange termijn. \n\n#### 4. Human before the loop\n\
  Hier maakt de mens vooraf ethische en morele afwegingen die in het algoritme zelf\
  \ worden ingebouwd. Hoewel het model in productie autonoom opereert, zal de menselijke\
  \ input gedurende de ontwikkeling ervoor zorgen dat het model ook in complexe situaties\
  \ volgens de juiste (ethische) afwegingen keuzes en acties onderneemt.\n\nDit model\
  \ is essentieel in situaties waar menselijk ingrijpen tijdens de uitvoering niet\
  \ mogelijk is (wanneer er bijvoorbeeld weinig of helemaal geen tijd is om als mens\
  \ te interveniëren), maar waar ethische keuzes cruciaal blijven. Denk aan bestrijding\
  \ van zeemijnen of situaties met zelfrijdende auto’s in onvoorspelbare verkeerssituaties\
  \ (bron: [TNO visiestuk 2022](https://publications.tno.nl/publication/34640024/a05DMs/TNO-2022-visiestuk.pdf)).\
  \ Deze variant kan ook worden ingezet voor situaties waarin wel nog menselijk ingrijpen\
  \ mogelijk is. \n\nHet niet inrichten van passende menselijke controle leidt tot\
  \ onverantwoorde inzet van algoritmen en het niet voldoen aan wettelijke vereisten.\
  \ \n"
urn: urn:nl:ak:mtr:imp-03
language: nl
owners:
- organization: Algoritmekader
  name: ''
  email: ''
  role: ''
date: ''
url: https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/index.html
subject:
- menselijke-controle
- governance
suggested_roles:
- projectleider
- beleid-en-advies
lifecycle:
- ontwerp
- implementatie
- monitoring-en-beheer
links:
- urn:nl:ak:ver:avg-10
- urn:nl:ak:ver:grw-01
- urn:nl:ak:ver:aia-22
- urn:nl:ak:ver:awb-01
- urn:nl:ak:ver:aia-09
- urn:nl:ak:ver:aia-21
template:
  requirement: $REQUIREMENT
  remarks: $REMARKS
  status: $STATUS
  timestamp: $TIMESTAMP
  authors:
  - name: $AUTHOR.NAME
    email: $AUTHOR.EMAIL
    role: $AUTHOR.ROLE
