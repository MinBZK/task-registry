systemcard_path: .systemcard.requirements[]
schema_version: 1.1.0
name: Controleer de data op manipulatie en ongewenste afhankelijkheden
description: 'De dataset die gebruikt wordt om een model te (her)trainen moet periodiek
  gecontroleerd worden op manipulatie (data poisoning). Voorkom ongewenste afhankelijkheden.

  '
explanation: "Manipulatie van data wordt een “data poisoning” aanval genoemd [^1]\
  \ [^2] [^3]. Een kwaadwillende kan op verschillende manieren te werk gaan:\n\n-\
  \ Bewust verkeerde informatie aan de dataset toevoegen. Dit is bijvoorbeeld mogelijk\
  \ door als aanvaller zelf een foutieve dataset beschikbaar te stellen. Controleer\
  \ daarom goed of een afgenomen dataset de kenmerken heeft die je verwacht. Daarnaast\
  \ kun je ook nog verifiëren of bijvoorbeeld het proces waarmee de dataset vergaard\
  \ is op de juiste manier is uitgevoerd. Tot slot is het verstandig om te voorkomen\
  \ dat de dataset afhankelijk is van een enkele bron.\n- Een aanvaller kan een bestaande\
  \ dataset aanpassen, door bijvoorbeeld labels om te draaien. In dit geval moet een\
  \ aanvaller toegang krijgen tot de locatie van de dataset. Bescherming hiertegen\
  \ begint met algemene beveiligingsmaatregelen, bijvoorbeeld zoals beschreven in\
  \ de [BIO](../hulpmiddelen/BIO.md). Daarnaast moet er ook gekeken worden naar het\
  \ voorkomen van een insider aanval. Dit kan door selectief te zijn in het verlenen\
  \ van toegang tot de locatie van de data en bijvoorbeeld het toepassen van een vier-ogen\
  \ principe.\n- In lijn met het aanpassen van de dataset kan een aanvaller ook een\
  \ deel van de dataset verwijderen. Dit is naar verwachting makkelijker te realiseren\
  \ dan het selectief aanpassen van de data. Door bijvoorbeeld alle data over een\
  \ bepaalde groep personen uit de dataset te verwijderen functioneert het model minder\
  \ goed voor die groep. Controleer daarom of de dataset waarmee uiteindelijk getraind\
  \ wordt precies hetzelfde is als de origineel bedoelde data. Dit kan bijvoorbeeld\
  \ door middel van een handtekening die geverifieerd kan worden. \n\nOp deze manieren\
  \ kan een aanvaller een model slecht laten functioneren, of alleen fouten laten\
  \ maken op specifiek gekozen invoerwaarden.  Een aanvaller kan de trainingsdata\
  \ zo beïnvloeden dat nummerborden met een stip altijd foutief gelezen worden, waardoor\
  \ criminelen kentekencontroles kunnen ontwijken. In dit geval wordt ook wel gesproken\
  \ over een [“backdoor” aanval](4-owk-09-adversarial-aanvallen.md#backdoor).\n\n\
  ### Adversarial traning\nDaarnaast kan het principe van [adversarial training](https://arxiv.org/abs/1611.01236)\
  \ worden toegepast door zelf bewust foutieve invoerwaarden aan de trainingsdata\
  \ toe te voegen. \nDoor een algoritme hierop te laten trainen kan deze beter bestand\
  \ gemaakt worden tegen aanvallen tijdens het gebruik.\n\nEen aanvaller kan proberen\
  \ om de trainingsdataset te manipuleren om het uiteindelijke model doelbewust fouten\
  \ te laten maken. Dit kan leiden tot verkeerde antwoorden, vooroordelen of zelfs\
  \ kwetsbaarheden in het model.\n"
urn: urn:nl:ak:mtr:dat-11
language: nl
owners:
- organization: Algoritmekader
  name: ''
  email: ''
  role: ''
date: ''
url: https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-11-datamanipulatie/index.html
subject:
- data
- technische-robuustheid-en-veiligheid
suggested_roles:
- ontwikkelaar
- beleid-en-advies
lifecycle:
- dataverkenning-en-datapreparatie
- monitoring-en-beheer
links:
- urn:nl:ak:ver:aia-10
- urn:nl:ak:ver:aia-22
- urn:nl:ak:ver:aia-32
- urn:nl:ak:ver:bio-01
- urn:nl:ak:ver:avg-12
template:
  requirement: $REQUIREMENT
  remarks: $REMARKS
  status: $STATUS
  timestamp: $TIMESTAMP
  authors:
  - name: $AUTHOR.NAME
    email: $AUTHOR.EMAIL
    role: $AUTHOR.ROLE
