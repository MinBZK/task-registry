systemcard_path: .systemcard.requirements[]
schema_version: 1.1.0
name: Maak een lijst van de meest kwetsbare groepen en bescherm hen extra
description: 'Bepaal wat de impact van het in te zetten algoritme is voor betrokkenen
  (personen of groepen).

  Bepaal vervolgens of er groepen zijn waarbij de impact van het algoritme dermate
  groot kan zijn, dat het wenselijk is om deze groepen extra bescherming te bieden.

  '
explanation: "- Verschillende groepen kunnen op een andere manier geraakt worden door\
  \ het inzetten van een algoritme. Dit is afhankelijk van de context waarin het algoritme\
  \ wordt ingezet, en dient daardoor bij iedere toepassing opnieuw bekeken te worden.\
  \ \n- Bedenk wat er met de uitkomsten van het algoritme gedaan wordt, en wat de\
  \ consequenties daarvan zijn voor burgers. Hierbij kan gedacht worden aan de volgende\
  \ aspecten:\n    - Worden bepaalde groepen sneller gemonitord?\n    - Wat als het\
  \ model het fout heeft? \n    - Wordt het systeem gebruikt om informatie te verkrijgen,\
  \ om besluiten voor te bereiden of om zelfstandige besluiten te nemen en welke gevolgen\
  \ heeft dat voor de mate waarin het algoritme bepalend zal zijn in de praktijk?\
  \ \n    - Worden de gegevens veilig en vertrouwelijk behandeld; welke gevolgen zou\
  \ een datalek hebben voor groepen of categorieën personen?\n    - Worden data gedeeld\
  \ met andere partijen en wat is het gevaar dat die misbruik maken van de data met\
  \ negatieve gevolgen voor groepen of categorieën personen?\n- Houd hierbij ook rekening\
  \ met de impact van het in te zetten algoritme op de samenleving (vanuit sociaal,\
  \ democratisch en milieu/ecologisch perspectief).\n- Om de impact op groepen te\
  \ bepalen, kan het handig zijn een mensenrechtentoets zoals het [Impact Assessment\
  \ Mensenrechten en Algoritmes](https://open.overheid.nl/documenten/ronl-c3d7fe94-9c62-493f-b858-f56b5e246a94/pdf)\
  \ toe te passen. \n- Bepaal of er maatregelen genomen kunnen worden om de geïdentificeerde\
  \ groepen extra bescherming te bieden. Hierbij kan men denken aan de volgende aspecten:\
  \ Kan de (extra) administratieve druk voor bepaalde groepen worden weggenomen? Worden\
  \ resultaten van het algoritme naast de resultaten van een expert gelegd? Is het\
  \ wenselijk om een proces in te richten waarbij zowel algoritme als een expert een\
  \ uitkomst geven? Kunnen we de betreffende groep extra hulp aanbieden? Is het wenselijk\
  \ bij negatieve uitkomsten een vier-ogen-principe toe te passen? \n- De impact van\
  \ het algoritme op de groepen die geïdentificeerd worden in deze stap, kunnen mogelijk\
  \ onderzocht worden in een [biasanalyse](5-ver-02-biasanalyse.md). Daarbij kan geidentificeerd\
  \ worden of bepaalde groepen oververtegenwoordigd of ondervertegenwoordigd zijn\
  \ in selecties, of dat het algoritme andere of meer fouten maakt voor bepaalde groepen.\
  \ \n- Merk op dat het onmogelijk is om de risico's voor alle specifieke groepen\
  \ af te vangen. Hierbij kan het helpen om te focussen op de meest kwetsbare groepen.\
  \ \n\nDe impact van het algoritme op de besluitvorming en op personen, doelgroepen\
  \ en/of de samenleving is niet inzichtelijk, waardoor onvoldoende maatregelen zijn\
  \ getroffen om ongewenste effecten (zoals bias en discriminatie) te voorkomen. \n"
urn: urn:nl:ak:mtr:owp-07
language: nl
owners:
- organization: Algoritmekader
  name: ''
  email: ''
  role: ''
date: ''
url: https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-07-kwetsbare-groepen/index.html
subject:
- fundamentele-rechten
suggested_roles:
- beleid-en-advies
lifecycle:
- ontwerp
links:
- urn:nl:ak:ver:grw-01
- urn:nl:ak:ver:aia-04
template:
  requirement: $REQUIREMENT
  remarks: $REMARKS
  status: $STATUS
  timestamp: $TIMESTAMP
  authors:
  - name: $AUTHOR.NAME
    email: $AUTHOR.EMAIL
    role: $AUTHOR.ROLE
